# ✅ User Profile Settings
user_profile:
  medium_username: "codingoni"  # Replace with your Medium username
  target_audience: "Non Technical People Looking For Tech Thought Leadership"  # Replace with your target audience
  professional_summary: "I'm a Software Engineer with a passion for creating innovative solutions and sharing my knowledge with the world. I'm always looking for new ways to improve my skills and help others do the same."  # Replace with your professional summary
  resume_url: "https://www.linkedin.com/in/your-linkedin-url"  # Replace with your LinkedIn URL
  llm:
    Pollinations:
      # Common default settings
      default_model: "openai"
      seed: 42
      temperature: 0.7
      jsonMode: true
      private: true

      # OpenAI-Compatible Completion (POST to /openai)
      openai_compatible:
        endpoint: "/v1/chat/completions"
        model: "text-davinci-003"  # or https://platform.openai.com/docs/models
        prompt: "Your custom prompt"  # Dynamically replaced
        suffix: null
        best_of: 1
        echo: false
        frequency_penalty: 0.0
        presence_penalty: 0.0
        logit_bias: {}  # e.g., {"50256": -100} to block <|endoftext|>
        logprobs: null
        max_tokens: 256
        "n": 1
        seed: 42
        stop: null  # Can be a string or array of strings
        stream: false
        stream_options: null
        temperature: 0.7
        top_p: 1.0
        messages: [
          {"role": "system", "content": "You are a helpful assistant."},
          {"role": "user", "content": "What is artificial intelligence?"}
        ]
        audio: null  # Optional: For models like gpt-4o that can output audio
        function_call: null  # Deprecated in favor of tool_choice, still optional
        functions: []  # Deprecated, use tools instead if needed
        max_completion_tokens: 256  # Use instead of max_tokens for o-series models
        metadata: {}  # Optional: Custom key-value metadata
        modalities: ["text"]  # Or ["text", "audio"] for multimodal models
        parallel_tool_calls: true  # Enable or disable parallel function calls
        prediction: null  # Optional prediction configuration
        reasoning_effort: "medium"  # o-series models only: low | medium | high
        response_format: "json_object"  # JSON schema config or {type: "json_object"}
        service_tier: "auto"  # auto | default (relevant for Scale Tier users)
        store: false  # Whether to store the output for model distillation
        tool_choice: "auto"  # Controls tool usage: none, auto, or function spec
        tools: []  # List of callable functions (OpenAI function calling format)
        top_logprobs: null  # Used only if logprobs is true
        web_search_options: null  # Advanced: for search-augmented completions
        search_context_size: "medium"  # Guidance for search context
        user_location: null  # Structured approximate location for search
        user: "user_id_here"

      # Native Pollinations Completion (POST to /)
      native_post:
        endpoint: "https://text.pollinations.ai/"
        model: "mistral"
        messages:
          - role: "system"
            content: "You're a helpful assistant."
          - role: "user"
            content: "Your User Prompt"
        reasoning_effort: "medium"

      # Simple Pollinations GET Completion
      native_get:
        endpoint: "https://text.pollinations.ai/{prompt}"  # prompt will be URL encoded
        model: "mistral"
        system: "You're a helpful assistant."
        json: true
      
      pollinations_image_get:
        endpoint: "https://image.pollinations.ai/prompt/{prompt}"  # prompt will be URL encoded
        model: "flux"              # Options: flux, flux-realism, flux-anime, turbo, etc.
        seed: 42                   # Controls image randomness
        width: 1024                # Image width in pixels
        height: 1024               # Image height in pixels
        nologo: true               # Remove watermark if true
        private: true              # Make image generation private
        enhance: false             # Enhance quality (if supported)
        safe: true                 # Apply safety filters

    OpenAI:
      name: "gpt-4"
      text_model: "gpt-4o-mini"
      image_model: "dall-e-3"
      image_size: "1024x1024"
      temperature: 0.7  # Adjusts randomness of responses (0 = strict, 1 = creative)
      top_p: 0.95  # Adjusts the likelihood of the text_model generating the top response (0 = no bias, 1 = strict bias)
      response_format: "json" # json | text | auto
      tool: Null
      available_models: # List of available models for this provider Check https://platform.openai.com/docs/api-reference/models
        - "gpt-4o"
        - "gpt-4o-mini"
        - "o1"
        - "o3-mini"
        - "gpt-4.5-preview"
        - "o3-mini-2025-01-31"
        - "o1-2024-12-17"
        - "gpt-4o-mini-2024-07-18"
        - "gpt-4o-2024-11-20"
        - "gpt-4o-2024-08-06"
        - "gpt-4.5-preview-2025-02-27"
        - "gpt-4-turbo-preview"
        - "gpt-4-turbo-2024-04-09"
        - "gpt-4-turbo"
        - "gpt-4-1106-preview"
        - "gpt-4-0613"
        - "gpt-4-0125-preview"
        - "gpt-4"
        - "gpt-3.5-turbo-16k"
        - "gpt-3.5-turbo-1106"
        - "gpt-3.5-turbo-0125"
        - "gpt-3.5-turbo"

    #https://api-docs.deepseek.com/api/create-chat-completion
    DeepSeek:
      text_model: "deepseek-chat"  # Ensure this matches the model you intend to use
      presence_penalty: 0.0  # Float between -2 and 2
      frequency_penalty: 0.0  # Float between -2 and 2
      response_format: "json_object"  # "json_object" or "text"
      temperature: 0.7  # Float ≤ 2
      max_tokens: 500  # Integer between 1 and 8192
      tools: "function"  # Specify tools if applicable
      tool_choice: "auto"  # "none", "auto", or specific tool name
      top_p: 0.95  # Float between 0 and 1
      logprobs: false  # Boolean
      top_logprobs: 5  # Integer between 0 and 20
      available_models:
        - "deepseek-chat"
        - "deepseek-reasoner"


    Anthropic:
      text_model: "claude-3-sonnet-20240229"  # Default text_model
      temperature: 0.7  # Adjusts randomness (0 = strict, 1 = creative)
      max_tokens: 500  # Max tokens allowed per response
      top_p: 0.9  # Nucleus sampling (alternative to temperature)
      frequency_penalty: 0.0  # Controls repetition
      presence_penalty: 0.0  # Encourages new topics
      stop_sequences: []  # List of custom stop sequences
      system: "You're a professional copywriter helping turn blog posts into viral LinkedIn content."
      available_models:
        - "claude-3-7-sonnet-20250219"
        - "claude-3-5-haiku-20241022"
        - "claude-3-5-sonnet-20241022"
        - "claude-3-5-sonnet-20240620"
        - "claude-3-opus-20240229"
        - "claude-3-sonnet-20240229"
        - "claude-3-haiku-20240307"
      message_format:
        - role: "user"
          content: "Hello, world"

    HuggingFace:
        text_model: "mistralai/Mistral-7B-Instruct-v0.1"
        image_model: "runwayml/stable-diffusion-v1-5"
        video_model: "runwayml/stable-diffusion-v1-5"
        temperature: 0.7
        max_tokens: 500
        available_models:
          - "meta-llama/Meta-Llama-3-8B"
          - "mistralai/Mistral-7B-Instruct-v0.1"
          - "tiiuae/falcon-7b-instruct"
        available_tools:
          - "Audio Classification"
          - "Automatic Speech Recognition"
          - "Chat Completion"
          - "Feature Extraction"
          - "Fill Mask"
          - "Image Classification"
          - "Image Segmentation"
          - "Image to Image"
          - "Image-Text to Text"
          - "Object Detection"
          - "Question Answering"
          - "Summarization"
          - "Table Question Answering"
          - "Text Classification"
          - "Text Generation"
          - "Text to Image"
          - "Token Classification"
          - "Translation"
          - "Zero Shot Classification"
      # Cohere:
      #   enabled: false
      #   text_model: "command-r"
      #   temperature: 0.7
      #   max_tokens: 500
      #   available_models:
      #     - "command-r-plus"
      #     - "command-r"

      # Ollama:
      #   enabled: false
      #   text_model: "llama3:8b"
      #   temperature: 0.7
      #   max_tokens: 500
      #   available_models:
      #     - "llama3:8b"
      #     - "llama3:70b"
      #     - "mistral:7b"



    Custom:
      enabled: false
      text_model: "your-custom-text_model"
      temperature: 0.7
      max_tokens: 500
      url: "https://your-custom-api.com/v1/completions"
      headers:
        Authorization: "Bearer your_api_key"
        Content-Type: "application/json"
  # ✅ Creative Preferences (Visuals & Storytelling)


# ✅ Social Media Platforms
social_media_to_post_to:
  linkedin:
    enabled: true
    post_format: "Text"  # Options: Markdown, HTML, or None
    maximum_characters: 260  # Maximum number of characters allowed

# ✅ OpenAI Configuration & Content Generation
ai:
  custom_system_instructions: " Return EITHER a generated JSON image (Creative and ImageAsset) if a creative prompt is provided OR GifSearchTags if not—never both. "
  custom_user_instructions: "Example response: { \"Text\": \"Your message here.\", \"Creative\": \"[IMG] A relevant visual description.\", \"ImageAsset\": \"https://image.pollinations.ai/prompt/{description}?width={width}&height={height}&seed={seed}&model=flux&nologo=true\", \"Hashtags\": [\"#Relevant\", \"#Contextual\", \"#GeneralTopic\"] } or { \"Text\": \"Message.\", \"Hashtags\": [\"#tag\", \"#tag\", \"#tag\"], \"GifSearchTags\": [\"term one\", \"term two\", \"term three\"] }"  # Optional user-level AI guidance

  text:
    generate_text:
      enabled: true
      user_description: "If true, generates a tailored AI Social Media Post and An Image Or Gif"
      width: 1024,
      height: 1024,
      prompt: "Create a high-quality AI-generated image relevant to the blog content."
      LLM: "Pollinations_Text_Advanced"
      # Available models: 'Pollinations', 'OpenAi', 'HuggingFace', 'DeepSeek', 'Claude'
  creative:
    generate_image:
      enabled: true
      user_description: "If true, generates a fallback image if the prompt fails to create one"
      width: 1024,
      height: 1024,
      prompt: "Create a high-quality AI-generated image relevant to the blog content."
      LLM: "Pollinations_Image_Get" # HuggingFace, OpenAI, Pollinations_Image_Get, Pollinations_Image 
      # Hugging Face Models: https://huggingface.co/models?pipeline_tag=text-to-image  && Flux Models: 'flux', 'flux-realism', 'any-dark', 'flux-anime', 'flux-3d', 'turbo'
      
    fetch_gif:
      enabled: false
      user_description: "If true, ai suggests tags from giphy then pick the giph with the most relevant title"
      prompt: "return atleast 3 giphy search terms in the returned object in an array"

# (Coming SOON)
    generate_video:
      enabled: false
      user_description: "If true, includes a video in the LinkedIn post to boost engagement."
      prompt: "Generate a video that highlights the key points of the blog post."

  viral_posting:
    include_viral_formatting:
      enabled: true
      description: "Ensures AI-generated posts follow viral structures."
      
    attention_grabbing_intro:
      enabled: true
      description: "First sentence must hook the reader to capture attention."
      
    emotional_storytelling:
      enabled: true
      description: "Includes personal/emotional elements to increase relatability."
      
    extreme_statements:
      enabled: false
      description: "Uses bold statements to spark engagement/debate (if enabled)."
      
    relatable_experiences:
      enabled: true
      description: "Ensures the post connects with the audience's daily struggles."
      
    actionable_takeaways:
      enabled: true
      description: "Posts must offer practical insights or solutions for readers."
      
    data-backed_claims:
      enabled: true
      description: "Uses real data & examples to establish credibility and trust."

  viral_posts_i_liked:
    - text: "I was rejected by 30 companies before landing my dream job. Now, I mentor others to never give up. 💪 #Resilience #CareerGrowth"
      engagement: "50K+ likes, 10K+ shares"
      creative: "[GIF] of a person overcoming obstacles"
      creative_asset: "https://example.com/obstacle-overcome.gif"
      reason: "Personal story of failure & success, highly relatable"
    
    - text: "AI won’t replace you. But a person using AI will. Are you adapting? 🚀 #ArtificialIntelligence #FutureOfWork"
      engagement: "50K+ likes, 10K+ shares"
      creative: "[IMG] Person Using AI"
      creative_asset: "https://example.com/obstacle-overcome.gif"

      reason: "Bold statement, sparks debate & FOMO"

    - text: "Quit my 6-figure job to chase my passion. Scariest but best decision ever. If you're stuck, this is your sign. 🔥 #CareerChange"
      engagement: 75K+ likes, 15K+ shares
      creative: "UGC Candid Video"
      reason: "Emotional + inspirational, triggers engagement"
      creative_asset: "https://example.com/obstacle-overcome.gif"

# ✅ Hashtags for Engagement
hashtags:
  default_tags:
    - "#AI"
    - "#MachineLearning"
    - "#DataScience"
    - "#Automation"
    - "#Technology"
  custom_tags: []  # Users can add their own custom hashtags here
